% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/functions.R
\name{create_classification}
\alias{create_classification}
\title{Create Classification - Beta
Classifies the specified query using provided examples.}
\usage{
create_classification(
  model,
  query,
  examples = NULL,
  expand = NULL,
  file = NULL,
  labels = NULL,
  logit_bias = NULL,
  logprobs = NULL,
  max_examples = NULL,
  return_metadata = NULL,
  return_prompt = NULL,
  search_model = NULL,
  temperature = NULL,
  return_response = F
)
}
\arguments{
\item{model}{(string) ID of the engine to use for completion. Required}

\item{query}{(string) Query to be classified. Required}

\item{examples}{(array) A list of examples with labels, in the following format: [\link{"The movie is so interesting.", "Positive"}, \link{"It is quite boring.", "Negative"}, ...] All the label strings will be normalized to be capitalized. You should specify either examples or file, but not both.}

\item{expand}{(array) If an object name is in the list, we provide the full information of the object; otherwise, we only provide the object ID. Currently we support completion and file objects for expansion.}

\item{file}{(string) The ID of the uploaded file that contains training examples. See upload file for how to upload a file of the desired format and purpose. You should specify either examples or file, but not both.}

\item{labels}{(array) The set of categories being classified. If not specified, candidate labels will be automatically collected from the examples you provide. All the label strings will be normalized to be capitalized.}

\item{logit_bias}{(map) Modify the likelihood of specified tokens appearing in the completion. Accepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this tokenizer tool (which works for both GPT-2 and GPT-3) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token. As an example, you can pass {"50256": -100} to prevent the <|endoftext|> token from being generated.}

\item{logprobs}{(integer) Include the log probabilities on the logprobs most likely tokens, as well the chosen tokens. For example, if logprobs is 10, the API will return a list of the 10 most likely tokens. the API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response. When logprobs is set, completion will be automatically added into expand to get the logprobs.}

\item{max_examples}{(integer) The maximum number of examples to be ranked by Search when using file. Setting it to a higher value leads to improved accuracy but with increased latency and cost.}

\item{return_metadata}{(boolean) A special boolean flag for showing metadata. If set to true, each document entry in the returned JSON will contain a "metadata" field. This flag only takes effect when file is set.}

\item{return_prompt}{(boolean) If set to true, the returned JSON will include a "prompt" field containing the final prompt that was used to request a completion. This is mainly useful for debugging purposes.}

\item{search_model}{(string) ID of the engine to use for Search.}

\item{temperature}{(number) What sampling temperature to use. Higher values mean the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.}

\item{return_response}{(boolean) Whether to return the API response or parse the contents of the response. Defaults to FALSE (parse the response).}
}
\description{
Create Classification - Beta
Classifies the specified query using provided examples.
}
